{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"py-ddd-cqrs-microservice-boilerplate","title":"py-ddd-cqrs-microservice-boilerplate"},{"location":"#py-ddd-cqrs-microservice-boilerplate","text":"","title":"py-ddd-cqrs-microservice-boilerplate"},{"location":"Architecture/","text":"Architecture This application follows the architecture suggested in the Cosmic Python book: https://www.cosmicpython.com/ The Cosmic Python book provides guidelines to implement a good DDD architecture in python. The architecture of this project is NOT based on: the Active Record pattern (Django like) Exagonal Architecture (even though similarities can be found) Clean Architecture (even though similarities can be found) Please refer to the book's preface to check how this architecture relates to the ones I mentioned before. Architecture Decision Record This project includes a folder of Architecture Decision Records , check it out here . Modules The responsibilities in this API can be assigned to modules: Domain ( domain module) Adapters ( adapters module) Service Layer ( services module) Entrypoints ( entrypoints module) Domain domain implements the Ubiquitous Language specific to our Domain. In this module are included only Pure python classes and functions that aim to have no infrastructure dependencies ( frameworks, persistence, data transfer etc). This module has to remain portable to any other python project and testable as a unit. The module is further divided in 2 modules: models , including the classes that implement DDD's Entities and ValueObjects Please check the paragraph \"Not Everything Has to Be an Object: A Domain Service Function\" from the Cosmic Python's 1st chapter Best quote: Sometimes, it just isn\u2019t a thing. \u2014 Eric Evans, Domain-Driven Design Please check the Domain documentation page for more details. Adapters adapters implements the \"adaptation\" to the foundation/backing services. As a pattern they implement the following: An interface that has to be used by all the clients, unaware of technological details A concrete implementation on top of a specific technology The goal is to provide an easy to swap set of adaptation objects to protect the code from changes in technological choices. The Adapters module includes the Repository classes. A Repository is a simplifying abstraction over data storage, allowing us to decouple our model module from the data module. The repositories in this module are implemented using the Adapter pattern. Please check the paragraph \"Repository Pattern\" from the Cosmic Python's 2nd chapter Service Layer services uses the Adapters and the Domain to implement services used outside. The Services functions/classes implement a contract with external clients. Potentially only tests against the ServiceLayer surface (interface) should be granted since the internal implementation details of the domain model should remain hidden to external clients. You can consider the services at the same level of the UseCases of the Exagonal Architecture/Clean Architecture. Their interface should never expose domain objects outside and should not accept them as parameters. For this reason all the services implemented in this project accept/expose DTOs (Data Transfer Objects) that are not the domain objects, the structure of these objects is part of the \"contract\" of the service module. Their interface should allow the passage of Repositories from outside, following the Dependency Inversion principle ( SOLID). Entrypoints Entrypoints are the places we drive our application from. In the official ports and adapters terminology, these are adapters too, and are referred to as primary, driving, or outward-facing adapters. entrypoints is the module (and the only one) that is dependent from technological choices related to the web technology one might want to choose. In a well implemented DDD architecture, all the technological choices are taken in the adapters/entrypoints modules. Some technologies might be used in the service module to facilitate serialization/deserialization and validation (pydantinc to implement the DTOs in our case). No technological dependencies are added to the domain module. Pure classes/functions implemented using language functionalities as much as possible In this project we provide one entrypoint in the form of a web application server implemented with FastAPI.","title":"Architecture"},{"location":"Architecture/#architecture","text":"This application follows the architecture suggested in the Cosmic Python book: https://www.cosmicpython.com/ The Cosmic Python book provides guidelines to implement a good DDD architecture in python. The architecture of this project is NOT based on: the Active Record pattern (Django like) Exagonal Architecture (even though similarities can be found) Clean Architecture (even though similarities can be found) Please refer to the book's preface to check how this architecture relates to the ones I mentioned before.","title":"Architecture"},{"location":"Architecture/#architecture-decision-record","text":"This project includes a folder of Architecture Decision Records , check it out here .","title":"Architecture Decision Record"},{"location":"Architecture/#modules","text":"The responsibilities in this API can be assigned to modules: Domain ( domain module) Adapters ( adapters module) Service Layer ( services module) Entrypoints ( entrypoints module)","title":"Modules"},{"location":"Architecture/#domain","text":"domain implements the Ubiquitous Language specific to our Domain. In this module are included only Pure python classes and functions that aim to have no infrastructure dependencies ( frameworks, persistence, data transfer etc). This module has to remain portable to any other python project and testable as a unit. The module is further divided in 2 modules: models , including the classes that implement DDD's Entities and ValueObjects Please check the paragraph \"Not Everything Has to Be an Object: A Domain Service Function\" from the Cosmic Python's 1st chapter Best quote: Sometimes, it just isn\u2019t a thing. \u2014 Eric Evans, Domain-Driven Design Please check the Domain documentation page for more details.","title":"Domain"},{"location":"Architecture/#adapters","text":"adapters implements the \"adaptation\" to the foundation/backing services. As a pattern they implement the following: An interface that has to be used by all the clients, unaware of technological details A concrete implementation on top of a specific technology The goal is to provide an easy to swap set of adaptation objects to protect the code from changes in technological choices. The Adapters module includes the Repository classes. A Repository is a simplifying abstraction over data storage, allowing us to decouple our model module from the data module. The repositories in this module are implemented using the Adapter pattern. Please check the paragraph \"Repository Pattern\" from the Cosmic Python's 2nd chapter","title":"Adapters"},{"location":"Architecture/#service-layer","text":"services uses the Adapters and the Domain to implement services used outside. The Services functions/classes implement a contract with external clients. Potentially only tests against the ServiceLayer surface (interface) should be granted since the internal implementation details of the domain model should remain hidden to external clients. You can consider the services at the same level of the UseCases of the Exagonal Architecture/Clean Architecture. Their interface should never expose domain objects outside and should not accept them as parameters. For this reason all the services implemented in this project accept/expose DTOs (Data Transfer Objects) that are not the domain objects, the structure of these objects is part of the \"contract\" of the service module. Their interface should allow the passage of Repositories from outside, following the Dependency Inversion principle ( SOLID).","title":"Service Layer"},{"location":"Architecture/#entrypoints","text":"Entrypoints are the places we drive our application from. In the official ports and adapters terminology, these are adapters too, and are referred to as primary, driving, or outward-facing adapters. entrypoints is the module (and the only one) that is dependent from technological choices related to the web technology one might want to choose. In a well implemented DDD architecture, all the technological choices are taken in the adapters/entrypoints modules. Some technologies might be used in the service module to facilitate serialization/deserialization and validation (pydantinc to implement the DTOs in our case). No technological dependencies are added to the domain module. Pure classes/functions implemented using language functionalities as much as possible In this project we provide one entrypoint in the form of a web application server implemented with FastAPI.","title":"Entrypoints"},{"location":"Responsibilities/","text":"Responsibilities This page contains a brief description of each main class from this architecture ValueObject domain A domain model object that doesn't have an identity. Entity domain A domain model object that has an identity. Aggregate domain A domain model object that: * has an entity * defines a consistency boundary * aggregates all the other domain entities for this bounded context Only one Repository per Aggregate exists. Event domain A domain object that represents an event happened or going to happen on a domain object. Command domain A special kind of event that represents a request for a modification on a domain object. Repository adapters Retrieves and stores aggregates from and to the persistence technology. Event Handlers services Handle one specific event as part of a single distinct unit of work. Unit of Work services Creates a session/consistency context for modification operations on domain aggregates. Message Bus services Dispatches events to events handlers, collects new events and returns results Entry Point entrypoints A client of the message bus. Receives external inputs and converts them into Events or Commands to be handled by the message bus.","title":"Responsibilities"},{"location":"Responsibilities/#responsibilities","text":"This page contains a brief description of each main class from this architecture","title":"Responsibilities"},{"location":"Responsibilities/#valueobject-domain","text":"A domain model object that doesn't have an identity.","title":"ValueObject domain"},{"location":"Responsibilities/#entity-domain","text":"A domain model object that has an identity.","title":"Entity domain"},{"location":"Responsibilities/#aggregate-domain","text":"A domain model object that: * has an entity * defines a consistency boundary * aggregates all the other domain entities for this bounded context Only one Repository per Aggregate exists.","title":"Aggregate domain"},{"location":"Responsibilities/#event-domain","text":"A domain object that represents an event happened or going to happen on a domain object.","title":"Event domain"},{"location":"Responsibilities/#command-domain","text":"A special kind of event that represents a request for a modification on a domain object.","title":"Command domain"},{"location":"Responsibilities/#repository-adapters","text":"Retrieves and stores aggregates from and to the persistence technology.","title":"Repository adapters"},{"location":"Responsibilities/#event-handlers-services","text":"Handle one specific event as part of a single distinct unit of work.","title":"Event Handlers services"},{"location":"Responsibilities/#unit-of-work-services","text":"Creates a session/consistency context for modification operations on domain aggregates.","title":"Unit of Work services"},{"location":"Responsibilities/#message-bus-services","text":"Dispatches events to events handlers, collects new events and returns results","title":"Message Bus services"},{"location":"Responsibilities/#entry-point-entrypoints","text":"A client of the message bus. Receives external inputs and converts them into Events or Commands to be handled by the message bus.","title":"Entry Point entrypoints"},{"location":"tests/","text":"Tests Organization The tests are organized in 3 groups: * E2E tests tests.e2e * Integration tests tests.integration * Unit tests tests.unit Context Given the definition for the following as in the Cosmic Python book (see Architecture ): * entrypoints (Web Server, CLI Tool, Messaging Job) * adapters (Database, caching system, external service mock) We follow the guidelines of the Cosmic Python book . E2E tests Definition : We define an e2e test as a test that executes code from all the \"ends\". In particular, requesting an operation from one entrypoint and reaching a concrete adapter. We aim to test the critical paths of the system looking at it as a black box. Example: Test --HTTP--> Entrypoint (Webserver App) -- ... --> Adapter (Repository) --> Testing/Local Database Integration tests Definition : We define an integration test a test that executes a unit integrated in the system. In particular, invoking a method of a unit which uses one of the adapters. Example: Test --Direct Invocation--> Class method/function --...--> Adapter (Repository) --> Testing/Local Database Unit tests Definition : We define a unit test a test test executes a unit mocking all the other adapters (if needed). Example: Test --Direct Invocation--> Class method/function --...--> MockedAdapter (MockedRepository) Mocks Versus Fakes; Classic-Style Versus London-School TDD In this project we prefer the Classic-Style: We like to build our tests around state both in setup and in assertions, and we like to work at the highest level of abstraction possible rather than doing checks on the behavior of intermediary collaborators. Quoting the Cosmic Python Book : We avoid using mocks in this book and in our production code too. We\u2019re not going to enter into a Holy War, but our instinct is that mocking frameworks, particularly monkeypatching, are a code smell. Instead, we like to clearly identify the responsibilities in our codebase, and to separate those responsibilities into small, focused objectsrequirements that are easy to replace with a test double.","title":"Tests"},{"location":"tests/#tests","text":"","title":"Tests"},{"location":"tests/#organization","text":"The tests are organized in 3 groups: * E2E tests tests.e2e * Integration tests tests.integration * Unit tests tests.unit","title":"Organization"},{"location":"tests/#context","text":"Given the definition for the following as in the Cosmic Python book (see Architecture ): * entrypoints (Web Server, CLI Tool, Messaging Job) * adapters (Database, caching system, external service mock) We follow the guidelines of the Cosmic Python book .","title":"Context"},{"location":"tests/#e2e-tests","text":"Definition : We define an e2e test as a test that executes code from all the \"ends\". In particular, requesting an operation from one entrypoint and reaching a concrete adapter. We aim to test the critical paths of the system looking at it as a black box. Example: Test --HTTP--> Entrypoint (Webserver App) -- ... --> Adapter (Repository) --> Testing/Local Database","title":"E2E tests"},{"location":"tests/#integration-tests","text":"Definition : We define an integration test a test that executes a unit integrated in the system. In particular, invoking a method of a unit which uses one of the adapters. Example: Test --Direct Invocation--> Class method/function --...--> Adapter (Repository) --> Testing/Local Database","title":"Integration tests"},{"location":"tests/#unit-tests","text":"Definition : We define a unit test a test test executes a unit mocking all the other adapters (if needed). Example: Test --Direct Invocation--> Class method/function --...--> MockedAdapter (MockedRepository)","title":"Unit tests"},{"location":"tests/#mocks-versus-fakes-classic-style-versus-london-school-tdd","text":"In this project we prefer the Classic-Style: We like to build our tests around state both in setup and in assertions, and we like to work at the highest level of abstraction possible rather than doing checks on the behavior of intermediary collaborators. Quoting the Cosmic Python Book : We avoid using mocks in this book and in our production code too. We\u2019re not going to enter into a Holy War, but our instinct is that mocking frameworks, particularly monkeypatching, are a code smell. Instead, we like to clearly identify the responsibilities in our codebase, and to separate those responsibilities into small, focused objectsrequirements that are easy to replace with a test double.","title":"Mocks Versus Fakes; Classic-Style Versus London-School TDD"},{"location":"adr/ADRs/","text":"Architectural Decision Record Status approved Context Design decisions tend to be forgotten during the course of a project. At any point in time new developers will need a place to describe problems, propose solutions, take decisions and evaluate consequences. Technical decisions evolve over time due to many reasons. Change of requirements, deprecation of technologies, new approaches are only some of the drivers for a technical change. Wherever a change is needed or not the first thing to asses is the status quo to understand how to move from the current situation to the new one. Is not unusual for software project to have technologies and design decisions that have been forgotten and cannot be explained. Decision For every relevant design decision create an Architectural Decision Record, add it to the code repository, and version it using the same version control system utilized by the codebase. Consequences This approach has several advantages: * The documentation is always close to the code * Anyone can create an ADR without the need of particular tooling * The ADRs can be implemented using the markdown syntax with all the advantages connected (rendering in github, possibility to generate websites etc.) * The ADRs are versioned together with the code so it's possible to track back when a decision has been added/modified/removed.","title":"ADRs"},{"location":"adr/ADRs/#architectural-decision-record","text":"","title":"Architectural Decision Record"},{"location":"adr/ADRs/#status","text":"approved","title":"Status"},{"location":"adr/ADRs/#context","text":"Design decisions tend to be forgotten during the course of a project. At any point in time new developers will need a place to describe problems, propose solutions, take decisions and evaluate consequences. Technical decisions evolve over time due to many reasons. Change of requirements, deprecation of technologies, new approaches are only some of the drivers for a technical change. Wherever a change is needed or not the first thing to asses is the status quo to understand how to move from the current situation to the new one. Is not unusual for software project to have technologies and design decisions that have been forgotten and cannot be explained.","title":"Context"},{"location":"adr/ADRs/#decision","text":"For every relevant design decision create an Architectural Decision Record, add it to the code repository, and version it using the same version control system utilized by the codebase.","title":"Decision"},{"location":"adr/ADRs/#consequences","text":"This approach has several advantages: * The documentation is always close to the code * Anyone can create an ADR without the need of particular tooling * The ADRs can be implemented using the markdown syntax with all the advantages connected (rendering in github, possibility to generate websites etc.) * The ADRs are versioned together with the code so it's possible to track back when a decision has been added/modified/removed.","title":"Consequences"},{"location":"adr/practices/000-Readiness%20probe/","text":"Implement liveliness, readiness and startup probes Status approved Context Cloud providers often rely on the usage of Orchestration systems over a containerization technology. The orchestration system needs to know at least 2 things about any service: If the service started correctly after a deployment If the service is still healthy at any moment in time Decision When implementing an API that has to be deployed on the cloud, implement the following endpoints: /ready an endpoint that returns a 200 - OK if the service is ready to accept requests after a new deployment /health an endpoint that returns a 200 - OK if the service is still alive and functioning correctly Consequences Thanks to this 2 endpoints is possible to deterministically and automatically detect problems both after a new deployment and during the normal operation of the service directly into the orchestration service. Check out this page for more info regarding how kubernetes can be configured for this https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-liveness-http-request","title":"Readiness Probe"},{"location":"adr/practices/000-Readiness%20probe/#implement-liveliness-readiness-and-startup-probes","text":"","title":"Implement liveliness, readiness and startup probes"},{"location":"adr/practices/000-Readiness%20probe/#status","text":"approved","title":"Status"},{"location":"adr/practices/000-Readiness%20probe/#context","text":"Cloud providers often rely on the usage of Orchestration systems over a containerization technology. The orchestration system needs to know at least 2 things about any service: If the service started correctly after a deployment If the service is still healthy at any moment in time","title":"Context"},{"location":"adr/practices/000-Readiness%20probe/#decision","text":"When implementing an API that has to be deployed on the cloud, implement the following endpoints: /ready an endpoint that returns a 200 - OK if the service is ready to accept requests after a new deployment /health an endpoint that returns a 200 - OK if the service is still alive and functioning correctly","title":"Decision"},{"location":"adr/practices/000-Readiness%20probe/#consequences","text":"Thanks to this 2 endpoints is possible to deterministically and automatically detect problems both after a new deployment and during the normal operation of the service directly into the orchestration service. Check out this page for more info regarding how kubernetes can be configured for this https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-liveness-http-request","title":"Consequences"},{"location":"adr/practices/001-Dependency%20inversion/","text":"Use Dependency Inversion Status approved Context Implementing a rest api often involves integrating external services such as databases or caches. In some cases it's necessary to call other apis to fetch data. The external dependencies might make unit-testing challenging. In such cases the natural solution is to provide mocks that simulate the behavior of the external service even without calling it. There are several approaches to provide the mocks (and the real implementations) to the services, some of the most used are: Direct import and monkey patching Dependency injection Dependency inversion Monkey patching is an approach that I don't recommend, please check the README.md in the tests folder for more info on that. Dependency injection requires the use of some technology that provides the dependencies in a \"transparent\" way and can be customized so that during testing the mocks are passed instead of the real dependencies. However, sometimes these technologies can feel like \"magic\" and hide the way they pass the dependencies to the actual code. Dependency inversion is a design approach in which the dependencies are explicitly passed from who constructs or invokes the unit to run/test. Decision I will use the dependency inversion approach, moving away to the previously used dependency injection approach. Consequences The dependency-injector package will be removed, the app will be built using a build_app function instead of being a module variable.","title":"Dependency Inversion"},{"location":"adr/practices/001-Dependency%20inversion/#use-dependency-inversion","text":"","title":"Use Dependency Inversion"},{"location":"adr/practices/001-Dependency%20inversion/#status","text":"approved","title":"Status"},{"location":"adr/practices/001-Dependency%20inversion/#context","text":"Implementing a rest api often involves integrating external services such as databases or caches. In some cases it's necessary to call other apis to fetch data. The external dependencies might make unit-testing challenging. In such cases the natural solution is to provide mocks that simulate the behavior of the external service even without calling it. There are several approaches to provide the mocks (and the real implementations) to the services, some of the most used are: Direct import and monkey patching Dependency injection Dependency inversion Monkey patching is an approach that I don't recommend, please check the README.md in the tests folder for more info on that. Dependency injection requires the use of some technology that provides the dependencies in a \"transparent\" way and can be customized so that during testing the mocks are passed instead of the real dependencies. However, sometimes these technologies can feel like \"magic\" and hide the way they pass the dependencies to the actual code. Dependency inversion is a design approach in which the dependencies are explicitly passed from who constructs or invokes the unit to run/test.","title":"Context"},{"location":"adr/practices/001-Dependency%20inversion/#decision","text":"I will use the dependency inversion approach, moving away to the previously used dependency injection approach.","title":"Decision"},{"location":"adr/practices/001-Dependency%20inversion/#consequences","text":"The dependency-injector package will be removed, the app will be built using a build_app function instead of being a module variable.","title":"Consequences"},{"location":"adr/practices/002-Domain%20Specific%20Exceptions/","text":"Use Domain Specific Exceptions Status approved Context As in life, also when developing APIs things do not always go as planned :) In such cases there are several approaches to handle failures in a function. Some of these are: Return objects Return None Raise exceptions There's no such thing as the right or wrong approach, and the discussion on using or not exceptions went so far that is honestly impossible to declare a \"clear winner\" in the industry. My personal opinion (and approach) is to: Use exceptions when things do not go as planned Wrap every \"expected\" exception with Domain Specific Exceptions Use the raise ... from e functionality in python to carry the entire stack of exceptions Allow \"unexpected\" exceptions to bubble up DO NOT use wide exception handling, let the webserver throw a 500, get notified for unhandled exceptions if the error should be \"expected\" create a Domain Specific Exception for it If not then the problem is somewhere else in the architecture, let it be unhandled, the code should fail fast and scream loud. Decision Use Domain Specific Exceptions, wrap all the expected cases, let the other exceptions bubble up and wrap them when encountered. Example Let's suppose to have the following: class PetNotFoundError(Exception): pass def get_pet_from_db(pet_id: UUID) -> Pet: try: return db.query(Pet).get(id=pet_id) except mydblibrary.errors.RowNotFoundError as e: raise PetNotFoundError() from e PetNotFoundError is the Domain Specific Exception, it represents what happened in the domain, and has no connection with any specific technology. mydblibrary.errors.RowNotFoundError is the \"expected\" technology specific exception. Let's now imagine the usage of this function from the api. @app.get(\"/pet/{pet_id}\") def get_pet_api(pet_id: UUID) -> Dict: try: pet = get_pet_from_db(pet_id) except PetNotFoundError as e: return HttpResponse(f\"Pet {pet_id} was not found\", status_code=404) return HttpResponse(to_json(pet), status_code=200) Now let's suppose to receive an \"unexpected\" mydblibrary.errors.ConnectionFailedError , in this scenario get_pet_from_db will fail and whoever is using it will receive the ConnectionFailedError . In the case of the API use a mechanism to respond with a 500 to this exception, set in place a mechanism to notify the team when this happens and approach the situation as follows. If the problem is due to some temporary problem, solve that problem and let the api fail fast and notify the team. If instead is an error that should be \"expected\", create another Domain Specific Exception and handle the error with a consistent return code.","title":"Domain Specific Exceptions"},{"location":"adr/practices/002-Domain%20Specific%20Exceptions/#use-domain-specific-exceptions","text":"","title":"Use Domain Specific Exceptions"},{"location":"adr/practices/002-Domain%20Specific%20Exceptions/#status","text":"approved","title":"Status"},{"location":"adr/practices/002-Domain%20Specific%20Exceptions/#context","text":"As in life, also when developing APIs things do not always go as planned :) In such cases there are several approaches to handle failures in a function. Some of these are: Return objects Return None Raise exceptions There's no such thing as the right or wrong approach, and the discussion on using or not exceptions went so far that is honestly impossible to declare a \"clear winner\" in the industry. My personal opinion (and approach) is to: Use exceptions when things do not go as planned Wrap every \"expected\" exception with Domain Specific Exceptions Use the raise ... from e functionality in python to carry the entire stack of exceptions Allow \"unexpected\" exceptions to bubble up DO NOT use wide exception handling, let the webserver throw a 500, get notified for unhandled exceptions if the error should be \"expected\" create a Domain Specific Exception for it If not then the problem is somewhere else in the architecture, let it be unhandled, the code should fail fast and scream loud.","title":"Context"},{"location":"adr/practices/002-Domain%20Specific%20Exceptions/#decision","text":"Use Domain Specific Exceptions, wrap all the expected cases, let the other exceptions bubble up and wrap them when encountered.","title":"Decision"},{"location":"adr/practices/002-Domain%20Specific%20Exceptions/#example","text":"Let's suppose to have the following: class PetNotFoundError(Exception): pass def get_pet_from_db(pet_id: UUID) -> Pet: try: return db.query(Pet).get(id=pet_id) except mydblibrary.errors.RowNotFoundError as e: raise PetNotFoundError() from e PetNotFoundError is the Domain Specific Exception, it represents what happened in the domain, and has no connection with any specific technology. mydblibrary.errors.RowNotFoundError is the \"expected\" technology specific exception. Let's now imagine the usage of this function from the api. @app.get(\"/pet/{pet_id}\") def get_pet_api(pet_id: UUID) -> Dict: try: pet = get_pet_from_db(pet_id) except PetNotFoundError as e: return HttpResponse(f\"Pet {pet_id} was not found\", status_code=404) return HttpResponse(to_json(pet), status_code=200) Now let's suppose to receive an \"unexpected\" mydblibrary.errors.ConnectionFailedError , in this scenario get_pet_from_db will fail and whoever is using it will receive the ConnectionFailedError . In the case of the API use a mechanism to respond with a 500 to this exception, set in place a mechanism to notify the team when this happens and approach the situation as follows. If the problem is due to some temporary problem, solve that problem and let the api fail fast and notify the team. If instead is an error that should be \"expected\", create another Domain Specific Exception and handle the error with a consistent return code.","title":"Example"},{"location":"adr/technologies/000-FastAPI/","text":"Fast API as Rest API framework Status approved Context Python provides several frameworks to develop RESTful APIs. All of them have their pro and cons and fit different scenarios. In this project we have the following functional requirements: * we want to build a REST API * we don't need templating or HTML rendering features * we need an OpenAPI specification exposed from the API * we need a validation framework for input data * we need a serialization framework for output data * OPT we need an automated mechanism to keep in sync the OpenAPI spec with the implementation In this project we have the following non-functional requirements: * we need a small memory consumption, in this way we can replicate the api in several containers * OPT we need support for asynchronous handling of HTTP requests, in this way we can reduce the number of replicas in high I/O bound performance scenarios Solution Use FastAPI as a REST framework. FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.6+ based on standard Python type hints. - Pydantic Website It checks all the functional and non-functional requirements. Furthermore: * uses the python typing module to implement validation * supports the Pydantic Models to implement validation * supports the Pydantic Models to implement serialization * uses the pythondocs and the Pydantic models to automatically generate the OpenAPI specification and the Swagger-UI/Redoc sites. Is developed on top of Starlette which is developed from the creators of django-rest-framework and adds the support for a typing based web development leveraging on pydantic Models. Consequences FastAPI is based on the ASGI (Asynchronous Standard Gateway Interface). FastAPI provides an application object that can be used by any ASGI compatible webservers. An ASGI compatible webserver has to be choosen to run FastAPI apps. Another consequence of choosing FastAPI is the suggestion to use pydantic as Data Transfer Objects framework so that the integration will be natural and will also generate documentation that will be up-to-date with the current implementation.","title":"Fast API"},{"location":"adr/technologies/000-FastAPI/#fast-api-as-rest-api-framework","text":"","title":"Fast API as Rest API framework"},{"location":"adr/technologies/000-FastAPI/#status","text":"approved","title":"Status"},{"location":"adr/technologies/000-FastAPI/#context","text":"Python provides several frameworks to develop RESTful APIs. All of them have their pro and cons and fit different scenarios. In this project we have the following functional requirements: * we want to build a REST API * we don't need templating or HTML rendering features * we need an OpenAPI specification exposed from the API * we need a validation framework for input data * we need a serialization framework for output data * OPT we need an automated mechanism to keep in sync the OpenAPI spec with the implementation In this project we have the following non-functional requirements: * we need a small memory consumption, in this way we can replicate the api in several containers * OPT we need support for asynchronous handling of HTTP requests, in this way we can reduce the number of replicas in high I/O bound performance scenarios","title":"Context"},{"location":"adr/technologies/000-FastAPI/#solution","text":"Use FastAPI as a REST framework. FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.6+ based on standard Python type hints. - Pydantic Website It checks all the functional and non-functional requirements. Furthermore: * uses the python typing module to implement validation * supports the Pydantic Models to implement validation * supports the Pydantic Models to implement serialization * uses the pythondocs and the Pydantic models to automatically generate the OpenAPI specification and the Swagger-UI/Redoc sites. Is developed on top of Starlette which is developed from the creators of django-rest-framework and adds the support for a typing based web development leveraging on pydantic Models.","title":"Solution"},{"location":"adr/technologies/000-FastAPI/#consequences","text":"FastAPI is based on the ASGI (Asynchronous Standard Gateway Interface). FastAPI provides an application object that can be used by any ASGI compatible webservers. An ASGI compatible webserver has to be choosen to run FastAPI apps. Another consequence of choosing FastAPI is the suggestion to use pydantic as Data Transfer Objects framework so that the integration will be natural and will also generate documentation that will be up-to-date with the current implementation.","title":"Consequences"},{"location":"adr/technologies/001-Pydantic/","text":"Pydantic for Data Transfer Objects, Validation and Serialization Status approved Context Python is a dynamically typed language that has an extremely powerful data structure, the dictionary (a.k.a. dict ). Whereas the dict is a good choice for many scenarios I think that its usage was abused throughout the python projects I encountered in my career. In many cases, data received from a http endpoint through parameters or POST body is represented in the code as a dict. The same can be said for data returned from a Rest API that adopts the JSON format as response. The simplicity of creating new dicts with literals often wins against the creation and the initialization of a dedicated class. This though brings, after some time, to problems related to the validation and the documentation of what a dict instance contains throughout the code, problem that gets even worse when passing the same dictionary throughout a deep stack of function calls. Solution Use pydantic to represent data objects and validate your data. Pydantic leverages on the combined power of: * Python 3's type annotations * dataclasses automatic constructors * A validation framework based on reflection, that can be extended further using @decorators Consequences For each endpoint that you define: * Define an input data type using the pydantic.BaseModel class * Define the output data type using the pydantic.Basemodel class Example import json from typing import Optional from pydantic import BaseModel class MyEndpointInputDTO(BaseModel): my_resource_filter_id: str limit: Optional[int]=0 offset: Optional[int]=0 class MyEndpointResourceDTO(BaseModel): id:str name:str age:int def my_get_endpoint(params:dict) -> dict: input_data =MyEndpointInputDTO(**params) # ... do whatever ... my_resources = inner_function() return json.dumps([resource.dict() for resource in my_resources]) As you can see the code results really clean in the happy path. Now if we want to handle the validation of the input parameters we just need to handle and exception from pydantic . def my_get_endpoint(params:dict) -> dict: try: input_data=MyEndpointInputDTO(**params) except ValidationError as e: return BadRequestResponse(e.json()) # ... do whatever ... my_resources= inner_function() return json.dumps([resource.json() for resource in my_resources]) And this will return something like: [ { \"loc\": [ \"my_resource_filter_id\" ], \"msg\": \"field required\", \"type\": \"value_error.missing\" }, { \"loc\": [ \"limit\" ], \"msg\": \"invalid int format\", \"type\": \"value_error.int\" } ]","title":"Pydantic"},{"location":"adr/technologies/001-Pydantic/#pydantic-for-data-transfer-objects-validation-and-serialization","text":"","title":"Pydantic for Data Transfer Objects, Validation and Serialization"},{"location":"adr/technologies/001-Pydantic/#status","text":"approved","title":"Status"},{"location":"adr/technologies/001-Pydantic/#context","text":"Python is a dynamically typed language that has an extremely powerful data structure, the dictionary (a.k.a. dict ). Whereas the dict is a good choice for many scenarios I think that its usage was abused throughout the python projects I encountered in my career. In many cases, data received from a http endpoint through parameters or POST body is represented in the code as a dict. The same can be said for data returned from a Rest API that adopts the JSON format as response. The simplicity of creating new dicts with literals often wins against the creation and the initialization of a dedicated class. This though brings, after some time, to problems related to the validation and the documentation of what a dict instance contains throughout the code, problem that gets even worse when passing the same dictionary throughout a deep stack of function calls.","title":"Context"},{"location":"adr/technologies/001-Pydantic/#solution","text":"Use pydantic to represent data objects and validate your data. Pydantic leverages on the combined power of: * Python 3's type annotations * dataclasses automatic constructors * A validation framework based on reflection, that can be extended further using @decorators","title":"Solution"},{"location":"adr/technologies/001-Pydantic/#consequences","text":"For each endpoint that you define: * Define an input data type using the pydantic.BaseModel class * Define the output data type using the pydantic.Basemodel class Example import json from typing import Optional from pydantic import BaseModel class MyEndpointInputDTO(BaseModel): my_resource_filter_id: str limit: Optional[int]=0 offset: Optional[int]=0 class MyEndpointResourceDTO(BaseModel): id:str name:str age:int def my_get_endpoint(params:dict) -> dict: input_data =MyEndpointInputDTO(**params) # ... do whatever ... my_resources = inner_function() return json.dumps([resource.dict() for resource in my_resources]) As you can see the code results really clean in the happy path. Now if we want to handle the validation of the input parameters we just need to handle and exception from pydantic . def my_get_endpoint(params:dict) -> dict: try: input_data=MyEndpointInputDTO(**params) except ValidationError as e: return BadRequestResponse(e.json()) # ... do whatever ... my_resources= inner_function() return json.dumps([resource.json() for resource in my_resources]) And this will return something like: [ { \"loc\": [ \"my_resource_filter_id\" ], \"msg\": \"field required\", \"type\": \"value_error.missing\" }, { \"loc\": [ \"limit\" ], \"msg\": \"invalid int format\", \"type\": \"value_error.int\" } ]","title":"Consequences"},{"location":"adr/tooling/001-pre-commit-hooks/","text":"Use pre-commit hooks for code-quality tooling Status accepted Context Adding some tools to the chain might cause developers to forget to run them at every commit. Decision To prevent this from happening we set-up pre-commit hooks using python pre-commit : https://pre-commit.com/. This will give us a way to specify our pre-commit hooks as a .yaml file and version them in the repo without the need of installing hooks in every machine. Consequences As soon as the repository is cloned and the dependencies are installed a developer will have to run pre-commit install to set up correctly the pre-commit hooks.","title":"Use pre-commit hooks for code-quality tooling"},{"location":"adr/tooling/001-pre-commit-hooks/#use-pre-commit-hooks-for-code-quality-tooling","text":"","title":"Use pre-commit hooks for code-quality tooling"},{"location":"adr/tooling/001-pre-commit-hooks/#status","text":"accepted","title":"Status"},{"location":"adr/tooling/001-pre-commit-hooks/#context","text":"Adding some tools to the chain might cause developers to forget to run them at every commit.","title":"Context"},{"location":"adr/tooling/001-pre-commit-hooks/#decision","text":"To prevent this from happening we set-up pre-commit hooks using python pre-commit : https://pre-commit.com/. This will give us a way to specify our pre-commit hooks as a .yaml file and version them in the repo without the need of installing hooks in every machine.","title":"Decision"},{"location":"adr/tooling/001-pre-commit-hooks/#consequences","text":"As soon as the repository is cloned and the dependencies are installed a developer will have to run pre-commit install to set up correctly the pre-commit hooks.","title":"Consequences"},{"location":"adr/tooling/002-code_formatter/","text":"Use an automated code formatter Status accepted Context When joining a new team, people coming from different environments might be used to different styles in writing code. This might seem trivial and also irrelevant but it actually affects a lot the productivity of a team in at least two ways: 1. A developer might write the code in its own style 2. A developer might discuss the code style of another developer Decision In order to avoid this confusion and to promote a consistent style I propose to use an automatic code formatter, in this case black : https://black.readthedocs.io/ Consequences Each developer will write code in its own style with the help of its own favourite tool. Before committing (or integrating black in the tool) the developer will have to format the code using the black command so that the style will be kept consistent. This can be further enforced using black as a commit pre-hook.","title":"Use an automated code formatter"},{"location":"adr/tooling/002-code_formatter/#use-an-automated-code-formatter","text":"","title":"Use an automated code formatter"},{"location":"adr/tooling/002-code_formatter/#status","text":"accepted","title":"Status"},{"location":"adr/tooling/002-code_formatter/#context","text":"When joining a new team, people coming from different environments might be used to different styles in writing code. This might seem trivial and also irrelevant but it actually affects a lot the productivity of a team in at least two ways: 1. A developer might write the code in its own style 2. A developer might discuss the code style of another developer","title":"Context"},{"location":"adr/tooling/002-code_formatter/#decision","text":"In order to avoid this confusion and to promote a consistent style I propose to use an automatic code formatter, in this case black : https://black.readthedocs.io/","title":"Decision"},{"location":"adr/tooling/002-code_formatter/#consequences","text":"Each developer will write code in its own style with the help of its own favourite tool. Before committing (or integrating black in the tool) the developer will have to format the code using the black command so that the style will be kept consistent. This can be further enforced using black as a commit pre-hook.","title":"Consequences"},{"location":"adr/tooling/003-code_linter/","text":"Use an automated code linter Status accepted Context When joining a new team, people coming from different environments might be used to different styles in writing code. This might seem trivial and also irrelevant but it actually affects a lot the productivity of a team in at least two ways: 1. A developer might write the code in its own style 2. A developer might discuss the code style of another developer Furthermore, some practices might be considered good in one team while being considered bad in another team. This creates an awkward situation in which some developers try to correct these bad practices in PRs without really succeding but increasing the level of frustration of their colleagues. Decision Proceed as follows: * define a set of rules that are considered good or bad practices, * discuss and agree on the minimum amount of rules at team level, * let an automatic linter block every commit in a pre-commit hook Use flake8 : https://flake8.pycqa.org/ for python. Consequences The linter will act as a cold rules checker, no more developers and hard feelings in enforcing the rules. At the same time, running it at a pre-commit-hook will make sure that code that is not compliant will not reach the repo at all. References https://adr.github.io/ https://github.com/joelparkerhenderson/architecture_decision_record","title":"Use an automated code linter"},{"location":"adr/tooling/003-code_linter/#use-an-automated-code-linter","text":"","title":"Use an automated code linter"},{"location":"adr/tooling/003-code_linter/#status","text":"accepted","title":"Status"},{"location":"adr/tooling/003-code_linter/#context","text":"When joining a new team, people coming from different environments might be used to different styles in writing code. This might seem trivial and also irrelevant but it actually affects a lot the productivity of a team in at least two ways: 1. A developer might write the code in its own style 2. A developer might discuss the code style of another developer Furthermore, some practices might be considered good in one team while being considered bad in another team. This creates an awkward situation in which some developers try to correct these bad practices in PRs without really succeding but increasing the level of frustration of their colleagues.","title":"Context"},{"location":"adr/tooling/003-code_linter/#decision","text":"Proceed as follows: * define a set of rules that are considered good or bad practices, * discuss and agree on the minimum amount of rules at team level, * let an automatic linter block every commit in a pre-commit hook Use flake8 : https://flake8.pycqa.org/ for python.","title":"Decision"},{"location":"adr/tooling/003-code_linter/#consequences","text":"The linter will act as a cold rules checker, no more developers and hard feelings in enforcing the rules. At the same time, running it at a pre-commit-hook will make sure that code that is not compliant will not reach the repo at all.","title":"Consequences"},{"location":"adr/tooling/003-code_linter/#references","text":"https://adr.github.io/ https://github.com/joelparkerhenderson/architecture_decision_record","title":"References"},{"location":"adr/tooling/004-license_checker/","text":"Use an automated license checker Status proposed Context Working with OpenSource software for commercial purposes requires every developer to check the licenses of the packages that he uses. Some licenses might be not-compatible with the project needs and cause some legal issue if not properly handled. Using open-source libraries speeds up development in a significant way but has a drawback, nested dependencies. Each open-source library could depend on further open-source libraries that could have different licenses for usage and re-distribution. Decision Given the previous concerns I suggest to use an automated licenses checker on the installed packages. In python you can use pip-licenses (which is distributed with MIT license) Consequences Anytime a new library is added to the project a developer can verify if a new/conflicting license has been added with that library or with a nested dependency. This allows the developer to take counter measures that can vary from mentioning the library in the list of open source technologies or deciding to not use that library at all.","title":"Use an automated license checker"},{"location":"adr/tooling/004-license_checker/#use-an-automated-license-checker","text":"","title":"Use an automated license checker"},{"location":"adr/tooling/004-license_checker/#status","text":"proposed","title":"Status"},{"location":"adr/tooling/004-license_checker/#context","text":"Working with OpenSource software for commercial purposes requires every developer to check the licenses of the packages that he uses. Some licenses might be not-compatible with the project needs and cause some legal issue if not properly handled. Using open-source libraries speeds up development in a significant way but has a drawback, nested dependencies. Each open-source library could depend on further open-source libraries that could have different licenses for usage and re-distribution.","title":"Context"},{"location":"adr/tooling/004-license_checker/#decision","text":"Given the previous concerns I suggest to use an automated licenses checker on the installed packages. In python you can use pip-licenses (which is distributed with MIT license)","title":"Decision"},{"location":"adr/tooling/004-license_checker/#consequences","text":"Anytime a new library is added to the project a developer can verify if a new/conflicting license has been added with that library or with a nested dependency. This allows the developer to take counter measures that can vary from mentioning the library in the list of open source technologies or deciding to not use that library at all.","title":"Consequences"}]}